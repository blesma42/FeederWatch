{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this file the data will be cleaned and transfored for further analysis.\n",
    "This will be done by connecting with the database and pass SQL querries through the connection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first, the required modules are imported:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import mysql.connector\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, the credentials are loaded and the connection to the database is etablished:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get credentials for MySQL/dbms\n",
    "with open(r'C:\\Users\\mathi\\Desktop\\Datenanalyse\\Credentials\\mysql.json') as json_file:\n",
    "    db_credentials = json.load(json_file)['MySQL']\n",
    "\n",
    "#credentials as variables\n",
    "host='localhost'\n",
    "user=db_credentials['user']\n",
    "password=db_credentials['password']\n",
    "database='feederwatch'\n",
    "\n",
    "#etablish connection to the dbms\n",
    "mydb = mysql.connector.connect(\n",
    "  host=host,\n",
    "  user=user,\n",
    "  password=password)\n",
    "\n",
    "mycursor = mydb.cursor()\n",
    "\n",
    "#select database\n",
    "query=f'USE {database}'\n",
    "mycursor.execute(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll check if all the tables are availible and how they are named."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('pfw_1988_1995_public',)\n",
      "('pfw_1996_2000_public',)\n",
      "('pfw_2001_2005_public',)\n",
      "('pfw_2006_2010_public',)\n",
      "('pfw_2011_2015_public',)\n",
      "('pfw_2016_2020_public',)\n",
      "('pfw_2021_public',)\n",
      "('pfw_count_site_data_public_2021',)\n"
     ]
    }
   ],
   "source": [
    "query='SHOW TABLES'\n",
    "mycursor.execute(query)\n",
    "for table in mycursor:\n",
    "    print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the names are just the ones from the original files, we can rename them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('pfw_1988',)\n",
      "('pfw_1996',)\n",
      "('pfw_2001',)\n",
      "('pfw_2006',)\n",
      "('pfw_2011',)\n",
      "('pfw_2016',)\n",
      "('pfw_2021',)\n",
      "('pfw_site_data',)\n"
     ]
    }
   ],
   "source": [
    "query='''RENAME TABLE\n",
    "        pfw_1988_1995_public TO pfw_1988,\n",
    "        pfw_1996_2000_public TO pfw_1996,\n",
    "        pfw_2001_2005_public TO pfw_2001,\n",
    "        pfw_2006_2010_public TO pfw_2006,\n",
    "        pfw_2011_2015_public TO pfw_2011,\n",
    "        pfw_2016_2020_public TO pfw_2016,\n",
    "        pfw_2021_public TO pfw_2021,\n",
    "        pfw_count_site_data_public_2021 TO pfw_site_data'''\n",
    "\n",
    "mycursor.execute(query)\n",
    "\n",
    "query='SHOW TABLES'\n",
    "mycursor.execute(query)\n",
    "for table in mycursor:\n",
    "    print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we expect that the tables with datafrom different years have the same structer, they are grouped together to acess them easily with loops later on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pfw_1996', 'pfw_2001', 'pfw_1988', 'pfw_2021', 'pfw_2016', 'pfw_2011', 'pfw_2006'}\n"
     ]
    }
   ],
   "source": [
    "observation_tables=set()\n",
    "query='SHOW TABLES'\n",
    "mycursor.execute(query)\n",
    "for table in mycursor:\n",
    "    observation_tables.add(table[0])\n",
    "\n",
    "observation_tables.discard('pfw_site_data') #removes site_data from set because it should be treated differently\n",
    "\n",
    "print(observation_tables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the observation tables should look all the same and contain a timestamp, we should be able to merge all these tables into a bigger one. Before this step is performed, we should control, if they all have the same column names and order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              pfw_1996            pfw_2001            pfw_1988  \\\n",
      "0                index               index               index   \n",
      "1               LOC_ID              LOC_ID              LOC_ID   \n",
      "2             LATITUDE            LATITUDE            LATITUDE   \n",
      "3            LONGITUDE           LONGITUDE           LONGITUDE   \n",
      "4    SUBNATIONAL1_CODE   SUBNATIONAL1_CODE   SUBNATIONAL1_CODE   \n",
      "5      ENTRY_TECHNIQUE     ENTRY_TECHNIQUE     ENTRY_TECHNIQUE   \n",
      "6               SUB_ID              SUB_ID              SUB_ID   \n",
      "7               OBS_ID              OBS_ID              OBS_ID   \n",
      "8                Month               Month               Month   \n",
      "9                  Day                 Day                 Day   \n",
      "10                Year                Year                Year   \n",
      "11      PROJ_PERIOD_ID      PROJ_PERIOD_ID      PROJ_PERIOD_ID   \n",
      "12        SPECIES_CODE        SPECIES_CODE        SPECIES_CODE   \n",
      "13            HOW_MANY            HOW_MANY            HOW_MANY   \n",
      "14           PLUS_CODE           PLUS_CODE           PLUS_CODE   \n",
      "15               VALID               VALID               VALID   \n",
      "16            REVIEWED            REVIEWED            REVIEWED   \n",
      "17             DAY1_AM             DAY1_AM             DAY1_AM   \n",
      "18             DAY1_PM             DAY1_PM             DAY1_PM   \n",
      "19             DAY2_AM             DAY2_AM             DAY2_AM   \n",
      "20             DAY2_PM             DAY2_PM             DAY2_PM   \n",
      "21  EFFORT_HRS_ATLEAST  EFFORT_HRS_ATLEAST  EFFORT_HRS_ATLEAST   \n",
      "22    SNOW_DEP_ATLEAST    SNOW_DEP_ATLEAST    SNOW_DEP_ATLEAST   \n",
      "23   Data_Entry_Method   Data_Entry_Method   Data_Entry_Method   \n",
      "\n",
      "              pfw_2021            pfw_2016            pfw_2011  \\\n",
      "0                index               index               index   \n",
      "1               loc_id              LOC_ID              LOC_ID   \n",
      "2             latitude            LATITUDE            LATITUDE   \n",
      "3            longitude           LONGITUDE           LONGITUDE   \n",
      "4    subnational1_code   SUBNATIONAL1_CODE   SUBNATIONAL1_CODE   \n",
      "5      entry_technique     ENTRY_TECHNIQUE     ENTRY_TECHNIQUE   \n",
      "6               sub_id              SUB_ID              SUB_ID   \n",
      "7               obs_id              OBS_ID              OBS_ID   \n",
      "8                Month               Month               Month   \n",
      "9                  Day                 Day                 Day   \n",
      "10                Year                Year                Year   \n",
      "11      PROJ_PERIOD_ID      PROJ_PERIOD_ID      PROJ_PERIOD_ID   \n",
      "12        species_code        SPECIES_CODE        SPECIES_CODE   \n",
      "13            how_many            HOW_MANY            HOW_MANY   \n",
      "14               valid           PLUS_CODE           PLUS_CODE   \n",
      "15            reviewed               VALID               VALID   \n",
      "16             day1_am            REVIEWED            REVIEWED   \n",
      "17             day1_pm             DAY1_AM             DAY1_AM   \n",
      "18             day2_am             DAY1_PM             DAY1_PM   \n",
      "19             day2_pm             DAY2_AM             DAY2_AM   \n",
      "20  effort_hrs_atleast             DAY2_PM             DAY2_PM   \n",
      "21    snow_dep_atleast  EFFORT_HRS_ATLEAST  EFFORT_HRS_ATLEAST   \n",
      "22   Data_Entry_Method    SNOW_DEP_ATLEAST    SNOW_DEP_ATLEAST   \n",
      "23                 NaN   Data_Entry_Method   Data_Entry_Method   \n",
      "\n",
      "              pfw_2006  \n",
      "0                index  \n",
      "1               LOC_ID  \n",
      "2             LATITUDE  \n",
      "3            LONGITUDE  \n",
      "4    SUBNATIONAL1_CODE  \n",
      "5      ENTRY_TECHNIQUE  \n",
      "6               SUB_ID  \n",
      "7               OBS_ID  \n",
      "8                Month  \n",
      "9                  Day  \n",
      "10                Year  \n",
      "11      PROJ_PERIOD_ID  \n",
      "12        SPECIES_CODE  \n",
      "13            HOW_MANY  \n",
      "14           PLUS_CODE  \n",
      "15               VALID  \n",
      "16            REVIEWED  \n",
      "17             DAY1_AM  \n",
      "18             DAY1_PM  \n",
      "19             DAY2_AM  \n",
      "20             DAY2_PM  \n",
      "21  EFFORT_HRS_ATLEAST  \n",
      "22    SNOW_DEP_ATLEAST  \n",
      "23   Data_Entry_Method  \n"
     ]
    }
   ],
   "source": [
    "column_names=pd.DataFrame()\n",
    "\n",
    "for table in observation_tables:\n",
    "    query=f'DESCRIBE {table}'\n",
    "    mycursor.execute(query)\n",
    "    columns=[]\n",
    "    for line in mycursor:\n",
    "        columns.append(line[0])\n",
    "    \n",
    "    temp_df=pd.DataFrame({table: columns})\n",
    "    column_names=pd.concat([column_names, temp_df], axis=1)\n",
    "\n",
    "print(column_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the output exceeds the size limit of a jupyter notbook cell, visual inspection won't work. \n",
    "Instead, a boolen matrix can be generated, where all column names are compared with each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          pfw_1996  pfw_2001  pfw_1988  pfw_2021  pfw_2016  pfw_2011  pfw_2006\n",
      "pfw_1996      True      True      True     False      True      True      True\n",
      "pfw_2001      True      True      True     False      True      True      True\n",
      "pfw_1988      True      True      True     False      True      True      True\n",
      "pfw_2021     False     False     False     False     False     False     False\n",
      "pfw_2016      True      True      True     False      True      True      True\n",
      "pfw_2011      True      True      True     False      True      True      True\n",
      "pfw_2006      True      True      True     False      True      True      True\n"
     ]
    }
   ],
   "source": [
    "as_np_array = column_names.values\n",
    "comparison_matrix = pd.DataFrame((as_np_array.T[:, None] == as_np_array.T).all(-1), column_names.columns, column_names.columns)\n",
    "print(comparison_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the comparison we can tell, that all tables have the same column names except 'pfw_2021'. For further investigation, we'll display the column names of 'pfw_2021' next to the names from another table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pfw_2021</th>\n",
       "      <th>pfw_1988</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>index</td>\n",
       "      <td>index</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>loc_id</td>\n",
       "      <td>LOC_ID</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>latitude</td>\n",
       "      <td>LATITUDE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>longitude</td>\n",
       "      <td>LONGITUDE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>subnational1_code</td>\n",
       "      <td>SUBNATIONAL1_CODE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>entry_technique</td>\n",
       "      <td>ENTRY_TECHNIQUE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>sub_id</td>\n",
       "      <td>SUB_ID</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>obs_id</td>\n",
       "      <td>OBS_ID</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Month</td>\n",
       "      <td>Month</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Day</td>\n",
       "      <td>Day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Year</td>\n",
       "      <td>Year</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>PROJ_PERIOD_ID</td>\n",
       "      <td>PROJ_PERIOD_ID</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>species_code</td>\n",
       "      <td>SPECIES_CODE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>how_many</td>\n",
       "      <td>HOW_MANY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>valid</td>\n",
       "      <td>PLUS_CODE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>reviewed</td>\n",
       "      <td>VALID</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>day1_am</td>\n",
       "      <td>REVIEWED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>day1_pm</td>\n",
       "      <td>DAY1_AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>day2_am</td>\n",
       "      <td>DAY1_PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>day2_pm</td>\n",
       "      <td>DAY2_AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>effort_hrs_atleast</td>\n",
       "      <td>DAY2_PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>snow_dep_atleast</td>\n",
       "      <td>EFFORT_HRS_ATLEAST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Data_Entry_Method</td>\n",
       "      <td>SNOW_DEP_ATLEAST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Data_Entry_Method</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              pfw_2021            pfw_1988\n",
       "0                index               index\n",
       "1               loc_id              LOC_ID\n",
       "2             latitude            LATITUDE\n",
       "3            longitude           LONGITUDE\n",
       "4    subnational1_code   SUBNATIONAL1_CODE\n",
       "5      entry_technique     ENTRY_TECHNIQUE\n",
       "6               sub_id              SUB_ID\n",
       "7               obs_id              OBS_ID\n",
       "8                Month               Month\n",
       "9                  Day                 Day\n",
       "10                Year                Year\n",
       "11      PROJ_PERIOD_ID      PROJ_PERIOD_ID\n",
       "12        species_code        SPECIES_CODE\n",
       "13            how_many            HOW_MANY\n",
       "14               valid           PLUS_CODE\n",
       "15            reviewed               VALID\n",
       "16             day1_am            REVIEWED\n",
       "17             day1_pm             DAY1_AM\n",
       "18             day2_am             DAY1_PM\n",
       "19             day2_pm             DAY2_AM\n",
       "20  effort_hrs_atleast             DAY2_PM\n",
       "21    snow_dep_atleast  EFFORT_HRS_ATLEAST\n",
       "22   Data_Entry_Method    SNOW_DEP_ATLEAST\n",
       "23                 NaN   Data_Entry_Method"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_names[['pfw_2021', 'pfw_1988']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A obvious differnce is, that they are written in differnt casses (lower/upper). But because the case dosn't matter for merging the tables, we can ignore this difference. \n",
    "Another difference is visible in row 14, where one column s labeled 'valid' and the other 'PLUS_CODE'. It seems, that the column 'plus_code' is missing in 'pfw_2021', which leads to a shift and missmatch in all following columns and a NaN column at the end to fill up the data.\n",
    "To figure out, what the missing column 'plus_code' should ontain, we can check the FeederWatch_Data_Dictonary.xlsx provided by Project FeederWatch. \n",
    "According to this documentation it should contain a binary value:\n",
    ">\"Variable indicating if the total number of a species seen was larger than the value reported\".\n",
    "Even though this variable dosn't seem to be very interesting for analysis, we can keep it and create an empty column for the table, where it's missing.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "query='''ALTER TABLE pfw_2021\n",
    "        ADD COLUMN plus_code BINARY NULL\n",
    "        AFTER how_many'''\n",
    "mycursor.execute(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To confirm the change, we can run code from above again. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pfw_2021</th>\n",
       "      <th>pfw_1988</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>index</td>\n",
       "      <td>index</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>loc_id</td>\n",
       "      <td>LOC_ID</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>latitude</td>\n",
       "      <td>LATITUDE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>longitude</td>\n",
       "      <td>LONGITUDE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>subnational1_code</td>\n",
       "      <td>SUBNATIONAL1_CODE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>entry_technique</td>\n",
       "      <td>ENTRY_TECHNIQUE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>sub_id</td>\n",
       "      <td>SUB_ID</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>obs_id</td>\n",
       "      <td>OBS_ID</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Month</td>\n",
       "      <td>Month</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Day</td>\n",
       "      <td>Day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Year</td>\n",
       "      <td>Year</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>PROJ_PERIOD_ID</td>\n",
       "      <td>PROJ_PERIOD_ID</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>species_code</td>\n",
       "      <td>SPECIES_CODE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>how_many</td>\n",
       "      <td>HOW_MANY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>plus_code</td>\n",
       "      <td>PLUS_CODE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>valid</td>\n",
       "      <td>VALID</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>reviewed</td>\n",
       "      <td>REVIEWED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>day1_am</td>\n",
       "      <td>DAY1_AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>day1_pm</td>\n",
       "      <td>DAY1_PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>day2_am</td>\n",
       "      <td>DAY2_AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>day2_pm</td>\n",
       "      <td>DAY2_PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>effort_hrs_atleast</td>\n",
       "      <td>EFFORT_HRS_ATLEAST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>snow_dep_atleast</td>\n",
       "      <td>SNOW_DEP_ATLEAST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Data_Entry_Method</td>\n",
       "      <td>Data_Entry_Method</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              pfw_2021            pfw_1988\n",
       "0                index               index\n",
       "1               loc_id              LOC_ID\n",
       "2             latitude            LATITUDE\n",
       "3            longitude           LONGITUDE\n",
       "4    subnational1_code   SUBNATIONAL1_CODE\n",
       "5      entry_technique     ENTRY_TECHNIQUE\n",
       "6               sub_id              SUB_ID\n",
       "7               obs_id              OBS_ID\n",
       "8                Month               Month\n",
       "9                  Day                 Day\n",
       "10                Year                Year\n",
       "11      PROJ_PERIOD_ID      PROJ_PERIOD_ID\n",
       "12        species_code        SPECIES_CODE\n",
       "13            how_many            HOW_MANY\n",
       "14           plus_code           PLUS_CODE\n",
       "15               valid               VALID\n",
       "16            reviewed            REVIEWED\n",
       "17             day1_am             DAY1_AM\n",
       "18             day1_pm             DAY1_PM\n",
       "19             day2_am             DAY2_AM\n",
       "20             day2_pm             DAY2_PM\n",
       "21  effort_hrs_atleast  EFFORT_HRS_ATLEAST\n",
       "22    snow_dep_atleast    SNOW_DEP_ATLEAST\n",
       "23   Data_Entry_Method   Data_Entry_Method"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_names=pd.DataFrame()\n",
    "\n",
    "for table in observation_tables:\n",
    "    query=f'DESCRIBE {table}'\n",
    "    mycursor.execute(query)\n",
    "    columns=[]\n",
    "    for line in mycursor:\n",
    "        columns.append(line[0])\n",
    "    \n",
    "    temp_df=pd.DataFrame({table: columns})\n",
    "    column_names=pd.concat([column_names, temp_df], axis=1)\n",
    "\n",
    "column_names[['pfw_2021', 'pfw_1988']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5cc83d2eedb6ffb852fbb5dbaa9989f2c63275a766445ab272166a468a2180f7"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
