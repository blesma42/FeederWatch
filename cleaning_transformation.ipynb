{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this file the data will be cleaned and transfored for further analysis.\n",
    "This will be done by connecting with the database and pass SQL querries through the connection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first, the required modules are imported:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import mysql.connector\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, the credentials are loaded and the connection to the database is etablished:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get credentials for MySQL/dbms\n",
    "with open(r'C:\\Users\\mathi\\Desktop\\Datenanalyse\\Credentials\\mysql.json') as json_file:\n",
    "    db_credentials = json.load(json_file)['MySQL']\n",
    "\n",
    "#credentials as variables\n",
    "host='localhost'\n",
    "user=db_credentials['user']\n",
    "password=db_credentials['password']\n",
    "database='feederwatch'\n",
    "\n",
    "#etablish connection to the dbms\n",
    "mydb = mysql.connector.connect(\n",
    "  host=host,\n",
    "  user=user,\n",
    "  password=password)\n",
    "\n",
    "mycursor = mydb.cursor()\n",
    "\n",
    "#select database\n",
    "query=f'USE {database}'\n",
    "mycursor.execute(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll check if all the tables are availible and how they are named."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('observations',)\n",
      "('pfw_1988_1995_public',)\n",
      "('pfw_1996_2000_public',)\n",
      "('pfw_2001_2005_public',)\n",
      "('pfw_2006_2010_public',)\n",
      "('pfw_2011_2015_public',)\n",
      "('pfw_2016_2020_public',)\n",
      "('pfw_2021_public',)\n",
      "('pfw_count_site_data_public_2021',)\n"
     ]
    }
   ],
   "source": [
    "query='SHOW TABLES'\n",
    "mycursor.execute(query)\n",
    "for table in mycursor:\n",
    "    print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the names are just the ones from the original files, we can rename them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('observations',)\n",
      "('pfw_1988',)\n",
      "('pfw_1996',)\n",
      "('pfw_2001',)\n",
      "('pfw_2006',)\n",
      "('pfw_2011',)\n",
      "('pfw_2016',)\n",
      "('pfw_2021',)\n",
      "('pfw_site_data',)\n"
     ]
    }
   ],
   "source": [
    "query='''RENAME TABLE\n",
    "        pfw_1988_1995_public TO pfw_1988,\n",
    "        pfw_1996_2000_public TO pfw_1996,\n",
    "        pfw_2001_2005_public TO pfw_2001,\n",
    "        pfw_2006_2010_public TO pfw_2006,\n",
    "        pfw_2011_2015_public TO pfw_2011,\n",
    "        pfw_2016_2020_public TO pfw_2016,\n",
    "        pfw_2021_public TO pfw_2021,\n",
    "        pfw_count_site_data_public_2021 TO pfw_site_data'''\n",
    "\n",
    "mycursor.execute(query)\n",
    "\n",
    "query='SHOW TABLES'\n",
    "mycursor.execute(query)\n",
    "for table in mycursor:\n",
    "    print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we expect that the tables with datafrom different years have the same structer, they are grouped together to acess them easily with loops later on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pfw_1996', 'pfw_2001', 'pfw_2011', 'pfw_2006', 'pfw_2021', 'pfw_1988', 'observations', 'pfw_2016'}\n"
     ]
    }
   ],
   "source": [
    "observation_tables=set()\n",
    "query='SHOW TABLES'\n",
    "mycursor.execute(query)\n",
    "for table in mycursor:\n",
    "    observation_tables.add(table[0])\n",
    "\n",
    "observation_tables.discard('pfw_site_data') #removes site_data from set because it should be treated differently\n",
    "\n",
    "print(observation_tables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the observation tables should look all the same and contain a timestamp, we should be able to merge all these tables into a bigger one. Before this step is performed, we should control, if they all have the same column names and order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              pfw_1996            pfw_2001            pfw_2011  \\\n",
      "0                index               index               index   \n",
      "1               LOC_ID              LOC_ID              LOC_ID   \n",
      "2             LATITUDE            LATITUDE            LATITUDE   \n",
      "3            LONGITUDE           LONGITUDE           LONGITUDE   \n",
      "4    SUBNATIONAL1_CODE   SUBNATIONAL1_CODE   SUBNATIONAL1_CODE   \n",
      "5      ENTRY_TECHNIQUE     ENTRY_TECHNIQUE     ENTRY_TECHNIQUE   \n",
      "6               SUB_ID              SUB_ID              SUB_ID   \n",
      "7               OBS_ID              OBS_ID              OBS_ID   \n",
      "8                Month               Month               Month   \n",
      "9                  Day                 Day                 Day   \n",
      "10                Year                Year                Year   \n",
      "11      PROJ_PERIOD_ID      PROJ_PERIOD_ID      PROJ_PERIOD_ID   \n",
      "12        SPECIES_CODE        SPECIES_CODE        SPECIES_CODE   \n",
      "13            HOW_MANY            HOW_MANY            HOW_MANY   \n",
      "14           PLUS_CODE           PLUS_CODE           PLUS_CODE   \n",
      "15               VALID               VALID               VALID   \n",
      "16            REVIEWED            REVIEWED            REVIEWED   \n",
      "17             DAY1_AM             DAY1_AM             DAY1_AM   \n",
      "18             DAY1_PM             DAY1_PM             DAY1_PM   \n",
      "19             DAY2_AM             DAY2_AM             DAY2_AM   \n",
      "20             DAY2_PM             DAY2_PM             DAY2_PM   \n",
      "21  EFFORT_HRS_ATLEAST  EFFORT_HRS_ATLEAST  EFFORT_HRS_ATLEAST   \n",
      "22    SNOW_DEP_ATLEAST    SNOW_DEP_ATLEAST    SNOW_DEP_ATLEAST   \n",
      "23   Data_Entry_Method   Data_Entry_Method   Data_Entry_Method   \n",
      "\n",
      "              pfw_2006            pfw_2021            pfw_1988  \\\n",
      "0                index               index               index   \n",
      "1               LOC_ID              loc_id              LOC_ID   \n",
      "2             LATITUDE            latitude            LATITUDE   \n",
      "3            LONGITUDE           longitude           LONGITUDE   \n",
      "4    SUBNATIONAL1_CODE   subnational1_code   SUBNATIONAL1_CODE   \n",
      "5      ENTRY_TECHNIQUE     entry_technique     ENTRY_TECHNIQUE   \n",
      "6               SUB_ID              sub_id              SUB_ID   \n",
      "7               OBS_ID              obs_id              OBS_ID   \n",
      "8                Month               Month               Month   \n",
      "9                  Day                 Day                 Day   \n",
      "10                Year                Year                Year   \n",
      "11      PROJ_PERIOD_ID      PROJ_PERIOD_ID      PROJ_PERIOD_ID   \n",
      "12        SPECIES_CODE        species_code        SPECIES_CODE   \n",
      "13            HOW_MANY            how_many            HOW_MANY   \n",
      "14           PLUS_CODE               valid           PLUS_CODE   \n",
      "15               VALID            reviewed               VALID   \n",
      "16            REVIEWED             day1_am            REVIEWED   \n",
      "17             DAY1_AM             day1_pm             DAY1_AM   \n",
      "18             DAY1_PM             day2_am             DAY1_PM   \n",
      "19             DAY2_AM             day2_pm             DAY2_AM   \n",
      "20             DAY2_PM  effort_hrs_atleast             DAY2_PM   \n",
      "21  EFFORT_HRS_ATLEAST    snow_dep_atleast  EFFORT_HRS_ATLEAST   \n",
      "22    SNOW_DEP_ATLEAST   Data_Entry_Method    SNOW_DEP_ATLEAST   \n",
      "23   Data_Entry_Method                 NaN   Data_Entry_Method   \n",
      "\n",
      "          observations            pfw_2016  \n",
      "0                index               index  \n",
      "1               LOC_ID              LOC_ID  \n",
      "2             LATITUDE            LATITUDE  \n",
      "3            LONGITUDE           LONGITUDE  \n",
      "4    SUBNATIONAL1_CODE   SUBNATIONAL1_CODE  \n",
      "5      ENTRY_TECHNIQUE     ENTRY_TECHNIQUE  \n",
      "6               SUB_ID              SUB_ID  \n",
      "7               OBS_ID              OBS_ID  \n",
      "8                Month               Month  \n",
      "9                  Day                 Day  \n",
      "10                Year                Year  \n",
      "11      PROJ_PERIOD_ID      PROJ_PERIOD_ID  \n",
      "12        SPECIES_CODE        SPECIES_CODE  \n",
      "13            HOW_MANY            HOW_MANY  \n",
      "14           PLUS_CODE           PLUS_CODE  \n",
      "15               VALID               VALID  \n",
      "16            REVIEWED            REVIEWED  \n",
      "17             DAY1_AM             DAY1_AM  \n",
      "18             DAY1_PM             DAY1_PM  \n",
      "19             DAY2_AM             DAY2_AM  \n",
      "20             DAY2_PM             DAY2_PM  \n",
      "21  EFFORT_HRS_ATLEAST  EFFORT_HRS_ATLEAST  \n",
      "22    SNOW_DEP_ATLEAST    SNOW_DEP_ATLEAST  \n",
      "23   Data_Entry_Method   Data_Entry_Method  \n"
     ]
    }
   ],
   "source": [
    "column_names=pd.DataFrame()\n",
    "\n",
    "for table in observation_tables:\n",
    "    query=f'DESCRIBE {table}'\n",
    "    mycursor.execute(query)\n",
    "    columns=[]\n",
    "    for line in mycursor:\n",
    "        columns.append(line[0])\n",
    "    \n",
    "    temp_df=pd.DataFrame({table: columns})\n",
    "    column_names=pd.concat([column_names, temp_df], axis=1)\n",
    "\n",
    "print(column_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the output exceeds the size limit of a jupyter notebook cell (at least in VS Code), visual inspection won't work. \n",
    "Instead, a boolen matrix can be generated, where all column names are compared with each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              pfw_1996  pfw_2001  pfw_2011  pfw_2006  pfw_2021  pfw_1988  \\\n",
      "pfw_1996          True      True      True      True     False      True   \n",
      "pfw_2001          True      True      True      True     False      True   \n",
      "pfw_2011          True      True      True      True     False      True   \n",
      "pfw_2006          True      True      True      True     False      True   \n",
      "pfw_2021         False     False     False     False     False     False   \n",
      "pfw_1988          True      True      True      True     False      True   \n",
      "observations      True      True      True      True     False      True   \n",
      "pfw_2016          True      True      True      True     False      True   \n",
      "\n",
      "              observations  pfw_2016  \n",
      "pfw_1996              True      True  \n",
      "pfw_2001              True      True  \n",
      "pfw_2011              True      True  \n",
      "pfw_2006              True      True  \n",
      "pfw_2021             False     False  \n",
      "pfw_1988              True      True  \n",
      "observations          True      True  \n",
      "pfw_2016              True      True  \n"
     ]
    }
   ],
   "source": [
    "as_np_array = column_names.values\n",
    "comparison_matrix = pd.DataFrame((as_np_array.T[:, None] == as_np_array.T).all(-1), column_names.columns, column_names.columns)\n",
    "print(comparison_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the comparison we can tell, that all tables have the same column names except 'pfw_2021'. For further investigation, we'll display the column names of 'pfw_2021' next to the names from another table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pfw_2021</th>\n",
       "      <th>pfw_1988</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>index</td>\n",
       "      <td>index</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>loc_id</td>\n",
       "      <td>LOC_ID</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>latitude</td>\n",
       "      <td>LATITUDE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>longitude</td>\n",
       "      <td>LONGITUDE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>subnational1_code</td>\n",
       "      <td>SUBNATIONAL1_CODE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>entry_technique</td>\n",
       "      <td>ENTRY_TECHNIQUE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>sub_id</td>\n",
       "      <td>SUB_ID</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>obs_id</td>\n",
       "      <td>OBS_ID</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Month</td>\n",
       "      <td>Month</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Day</td>\n",
       "      <td>Day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Year</td>\n",
       "      <td>Year</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>PROJ_PERIOD_ID</td>\n",
       "      <td>PROJ_PERIOD_ID</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>species_code</td>\n",
       "      <td>SPECIES_CODE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>how_many</td>\n",
       "      <td>HOW_MANY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>valid</td>\n",
       "      <td>PLUS_CODE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>reviewed</td>\n",
       "      <td>VALID</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>day1_am</td>\n",
       "      <td>REVIEWED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>day1_pm</td>\n",
       "      <td>DAY1_AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>day2_am</td>\n",
       "      <td>DAY1_PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>day2_pm</td>\n",
       "      <td>DAY2_AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>effort_hrs_atleast</td>\n",
       "      <td>DAY2_PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>snow_dep_atleast</td>\n",
       "      <td>EFFORT_HRS_ATLEAST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Data_Entry_Method</td>\n",
       "      <td>SNOW_DEP_ATLEAST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Data_Entry_Method</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              pfw_2021            pfw_1988\n",
       "0                index               index\n",
       "1               loc_id              LOC_ID\n",
       "2             latitude            LATITUDE\n",
       "3            longitude           LONGITUDE\n",
       "4    subnational1_code   SUBNATIONAL1_CODE\n",
       "5      entry_technique     ENTRY_TECHNIQUE\n",
       "6               sub_id              SUB_ID\n",
       "7               obs_id              OBS_ID\n",
       "8                Month               Month\n",
       "9                  Day                 Day\n",
       "10                Year                Year\n",
       "11      PROJ_PERIOD_ID      PROJ_PERIOD_ID\n",
       "12        species_code        SPECIES_CODE\n",
       "13            how_many            HOW_MANY\n",
       "14               valid           PLUS_CODE\n",
       "15            reviewed               VALID\n",
       "16             day1_am            REVIEWED\n",
       "17             day1_pm             DAY1_AM\n",
       "18             day2_am             DAY1_PM\n",
       "19             day2_pm             DAY2_AM\n",
       "20  effort_hrs_atleast             DAY2_PM\n",
       "21    snow_dep_atleast  EFFORT_HRS_ATLEAST\n",
       "22   Data_Entry_Method    SNOW_DEP_ATLEAST\n",
       "23                 NaN   Data_Entry_Method"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_names[['pfw_2021', 'pfw_1988']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A obvious differnce is, that they are written in differnt casses (lower/upper). But because the case dosn't matter for merging the tables, we can ignore this difference. \n",
    "Another difference is visible in row 14, where one column s labeled 'valid' and the other 'PLUS_CODE'. It seems, that the column 'plus_code' is missing in 'pfw_2021', which leads to a shift and missmatch in all following columns and a NaN column at the end to fill up the data.\n",
    "To figure out, what the missing column 'plus_code' should ontain, we can check the FeederWatch_Data_Dictonary.xlsx provided by Project FeederWatch. \n",
    "According to this documentation it should contain a binary value:\n",
    "\n",
    ">\"Variable indicating if the total number of a species seen was larger than the value reported\".\n",
    "\n",
    "Even though this variable dosn't seem to be very interesting for analysis, we can keep it and create an empty column for the table, where it's missing.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "ProgrammingError",
     "evalue": "1064 (42000): You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near 'NULL\n        AFTER how_many' at line 2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMySQLInterfaceError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\mathi\\Desktop\\Datenanalyse\\.venv\\lib\\site-packages\\mysql\\connector\\connection_cext.py:523\u001b[0m, in \u001b[0;36mCMySQLConnection.cmd_query\u001b[1;34m(self, query, raw, buffered, raw_as_string)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/mathi/Desktop/Datenanalyse/.venv/lib/site-packages/mysql/connector/connection_cext.py?line=521'>522</a>\u001b[0m         query \u001b[39m=\u001b[39m query\u001b[39m.\u001b[39mencode(\u001b[39m'\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m--> <a href='file:///c%3A/Users/mathi/Desktop/Datenanalyse/.venv/lib/site-packages/mysql/connector/connection_cext.py?line=522'>523</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_cmysql\u001b[39m.\u001b[39;49mquery(query,\n\u001b[0;32m    <a href='file:///c%3A/Users/mathi/Desktop/Datenanalyse/.venv/lib/site-packages/mysql/connector/connection_cext.py?line=523'>524</a>\u001b[0m                        raw\u001b[39m=\u001b[39;49mraw, buffered\u001b[39m=\u001b[39;49mbuffered,\n\u001b[0;32m    <a href='file:///c%3A/Users/mathi/Desktop/Datenanalyse/.venv/lib/site-packages/mysql/connector/connection_cext.py?line=524'>525</a>\u001b[0m                        raw_as_string\u001b[39m=\u001b[39;49mraw_as_string,\n\u001b[0;32m    <a href='file:///c%3A/Users/mathi/Desktop/Datenanalyse/.venv/lib/site-packages/mysql/connector/connection_cext.py?line=525'>526</a>\u001b[0m                        query_attrs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_query_attrs)\n\u001b[0;32m    <a href='file:///c%3A/Users/mathi/Desktop/Datenanalyse/.venv/lib/site-packages/mysql/connector/connection_cext.py?line=526'>527</a>\u001b[0m \u001b[39mexcept\u001b[39;00m MySQLInterfaceError \u001b[39mas\u001b[39;00m exc:\n",
      "\u001b[1;31mMySQLInterfaceError\u001b[0m: You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near 'NULL\n        AFTER how_many' at line 2",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mProgrammingError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\mathi\\Desktop\\Datenanalyse\\2022-02-04_FeederWatch\\Project\\cleaning_transformation.ipynb Cell 19'\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/mathi/Desktop/Datenanalyse/2022-02-04_FeederWatch/Project/cleaning_transformation.ipynb#ch0000018?line=0'>1</a>\u001b[0m query\u001b[39m=\u001b[39m\u001b[39m'''\u001b[39m\u001b[39mALTER TABLE pfw_2021\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/mathi/Desktop/Datenanalyse/2022-02-04_FeederWatch/Project/cleaning_transformation.ipynb#ch0000018?line=1'>2</a>\u001b[0m \u001b[39m        ADD COLUMN plus_code NULL\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/mathi/Desktop/Datenanalyse/2022-02-04_FeederWatch/Project/cleaning_transformation.ipynb#ch0000018?line=2'>3</a>\u001b[0m \u001b[39m        AFTER how_many\u001b[39m\u001b[39m'''\u001b[39m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/mathi/Desktop/Datenanalyse/2022-02-04_FeederWatch/Project/cleaning_transformation.ipynb#ch0000018?line=3'>4</a>\u001b[0m mycursor\u001b[39m.\u001b[39;49mexecute(query)\n",
      "File \u001b[1;32mc:\\Users\\mathi\\Desktop\\Datenanalyse\\.venv\\lib\\site-packages\\mysql\\connector\\cursor_cext.py:269\u001b[0m, in \u001b[0;36mCMySQLCursor.execute\u001b[1;34m(self, operation, params, multi)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/mathi/Desktop/Datenanalyse/.venv/lib/site-packages/mysql/connector/cursor_cext.py?line=264'>265</a>\u001b[0m             \u001b[39mraise\u001b[39;00m errors\u001b[39m.\u001b[39mProgrammingError(\n\u001b[0;32m    <a href='file:///c%3A/Users/mathi/Desktop/Datenanalyse/.venv/lib/site-packages/mysql/connector/cursor_cext.py?line=265'>266</a>\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mNot all parameters were used in the SQL statement\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    <a href='file:///c%3A/Users/mathi/Desktop/Datenanalyse/.venv/lib/site-packages/mysql/connector/cursor_cext.py?line=267'>268</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> <a href='file:///c%3A/Users/mathi/Desktop/Datenanalyse/.venv/lib/site-packages/mysql/connector/cursor_cext.py?line=268'>269</a>\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_cnx\u001b[39m.\u001b[39;49mcmd_query(stmt, raw\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_raw,\n\u001b[0;32m    <a href='file:///c%3A/Users/mathi/Desktop/Datenanalyse/.venv/lib/site-packages/mysql/connector/cursor_cext.py?line=269'>270</a>\u001b[0m                                  buffered\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_buffered,\n\u001b[0;32m    <a href='file:///c%3A/Users/mathi/Desktop/Datenanalyse/.venv/lib/site-packages/mysql/connector/cursor_cext.py?line=270'>271</a>\u001b[0m                                  raw_as_string\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_raw_as_string)\n\u001b[0;32m    <a href='file:///c%3A/Users/mathi/Desktop/Datenanalyse/.venv/lib/site-packages/mysql/connector/cursor_cext.py?line=271'>272</a>\u001b[0m \u001b[39mexcept\u001b[39;00m MySQLInterfaceError \u001b[39mas\u001b[39;00m exc:\n\u001b[0;32m    <a href='file:///c%3A/Users/mathi/Desktop/Datenanalyse/.venv/lib/site-packages/mysql/connector/cursor_cext.py?line=272'>273</a>\u001b[0m     \u001b[39mraise\u001b[39;00m errors\u001b[39m.\u001b[39mget_mysql_exception(msg\u001b[39m=\u001b[39mexc\u001b[39m.\u001b[39mmsg, errno\u001b[39m=\u001b[39mexc\u001b[39m.\u001b[39merrno,\n\u001b[0;32m    <a href='file:///c%3A/Users/mathi/Desktop/Datenanalyse/.venv/lib/site-packages/mysql/connector/cursor_cext.py?line=273'>274</a>\u001b[0m                                      sqlstate\u001b[39m=\u001b[39mexc\u001b[39m.\u001b[39msqlstate)\n",
      "File \u001b[1;32mc:\\Users\\mathi\\Desktop\\Datenanalyse\\.venv\\lib\\site-packages\\mysql\\connector\\connection_cext.py:528\u001b[0m, in \u001b[0;36mCMySQLConnection.cmd_query\u001b[1;34m(self, query, raw, buffered, raw_as_string)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/mathi/Desktop/Datenanalyse/.venv/lib/site-packages/mysql/connector/connection_cext.py?line=522'>523</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cmysql\u001b[39m.\u001b[39mquery(query,\n\u001b[0;32m    <a href='file:///c%3A/Users/mathi/Desktop/Datenanalyse/.venv/lib/site-packages/mysql/connector/connection_cext.py?line=523'>524</a>\u001b[0m                        raw\u001b[39m=\u001b[39mraw, buffered\u001b[39m=\u001b[39mbuffered,\n\u001b[0;32m    <a href='file:///c%3A/Users/mathi/Desktop/Datenanalyse/.venv/lib/site-packages/mysql/connector/connection_cext.py?line=524'>525</a>\u001b[0m                        raw_as_string\u001b[39m=\u001b[39mraw_as_string,\n\u001b[0;32m    <a href='file:///c%3A/Users/mathi/Desktop/Datenanalyse/.venv/lib/site-packages/mysql/connector/connection_cext.py?line=525'>526</a>\u001b[0m                        query_attrs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_query_attrs)\n\u001b[0;32m    <a href='file:///c%3A/Users/mathi/Desktop/Datenanalyse/.venv/lib/site-packages/mysql/connector/connection_cext.py?line=526'>527</a>\u001b[0m \u001b[39mexcept\u001b[39;00m MySQLInterfaceError \u001b[39mas\u001b[39;00m exc:\n\u001b[1;32m--> <a href='file:///c%3A/Users/mathi/Desktop/Datenanalyse/.venv/lib/site-packages/mysql/connector/connection_cext.py?line=527'>528</a>\u001b[0m     \u001b[39mraise\u001b[39;00m errors\u001b[39m.\u001b[39mget_mysql_exception(exc\u001b[39m.\u001b[39merrno, msg\u001b[39m=\u001b[39mexc\u001b[39m.\u001b[39mmsg,\n\u001b[0;32m    <a href='file:///c%3A/Users/mathi/Desktop/Datenanalyse/.venv/lib/site-packages/mysql/connector/connection_cext.py?line=528'>529</a>\u001b[0m                                      sqlstate\u001b[39m=\u001b[39mexc\u001b[39m.\u001b[39msqlstate)\n\u001b[0;32m    <a href='file:///c%3A/Users/mathi/Desktop/Datenanalyse/.venv/lib/site-packages/mysql/connector/connection_cext.py?line=529'>530</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/mathi/Desktop/Datenanalyse/.venv/lib/site-packages/mysql/connector/connection_cext.py?line=530'>531</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_unix_socket:\n",
      "\u001b[1;31mProgrammingError\u001b[0m: 1064 (42000): You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near 'NULL\n        AFTER how_many' at line 2"
     ]
    }
   ],
   "source": [
    "query='''ALTER TABLE pfw_2021\n",
    "        ADD COLUMN plus_code BINARY NULL\n",
    "        AFTER how_many'''\n",
    "mycursor.execute(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To confirm the change, we can run code from above again. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pfw_2021</th>\n",
       "      <th>pfw_1988</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>index</td>\n",
       "      <td>index</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>loc_id</td>\n",
       "      <td>LOC_ID</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>latitude</td>\n",
       "      <td>LATITUDE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>longitude</td>\n",
       "      <td>LONGITUDE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>subnational1_code</td>\n",
       "      <td>SUBNATIONAL1_CODE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>entry_technique</td>\n",
       "      <td>ENTRY_TECHNIQUE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>sub_id</td>\n",
       "      <td>SUB_ID</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>obs_id</td>\n",
       "      <td>OBS_ID</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Month</td>\n",
       "      <td>Month</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Day</td>\n",
       "      <td>Day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Year</td>\n",
       "      <td>Year</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>PROJ_PERIOD_ID</td>\n",
       "      <td>PROJ_PERIOD_ID</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>species_code</td>\n",
       "      <td>SPECIES_CODE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>how_many</td>\n",
       "      <td>HOW_MANY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>plus_code</td>\n",
       "      <td>PLUS_CODE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>valid</td>\n",
       "      <td>VALID</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>reviewed</td>\n",
       "      <td>REVIEWED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>day1_am</td>\n",
       "      <td>DAY1_AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>day1_pm</td>\n",
       "      <td>DAY1_PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>day2_am</td>\n",
       "      <td>DAY2_AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>day2_pm</td>\n",
       "      <td>DAY2_PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>effort_hrs_atleast</td>\n",
       "      <td>EFFORT_HRS_ATLEAST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>snow_dep_atleast</td>\n",
       "      <td>SNOW_DEP_ATLEAST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Data_Entry_Method</td>\n",
       "      <td>Data_Entry_Method</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              pfw_2021            pfw_1988\n",
       "0                index               index\n",
       "1               loc_id              LOC_ID\n",
       "2             latitude            LATITUDE\n",
       "3            longitude           LONGITUDE\n",
       "4    subnational1_code   SUBNATIONAL1_CODE\n",
       "5      entry_technique     ENTRY_TECHNIQUE\n",
       "6               sub_id              SUB_ID\n",
       "7               obs_id              OBS_ID\n",
       "8                Month               Month\n",
       "9                  Day                 Day\n",
       "10                Year                Year\n",
       "11      PROJ_PERIOD_ID      PROJ_PERIOD_ID\n",
       "12        species_code        SPECIES_CODE\n",
       "13            how_many            HOW_MANY\n",
       "14           plus_code           PLUS_CODE\n",
       "15               valid               VALID\n",
       "16            reviewed            REVIEWED\n",
       "17             day1_am             DAY1_AM\n",
       "18             day1_pm             DAY1_PM\n",
       "19             day2_am             DAY2_AM\n",
       "20             day2_pm             DAY2_PM\n",
       "21  effort_hrs_atleast  EFFORT_HRS_ATLEAST\n",
       "22    snow_dep_atleast    SNOW_DEP_ATLEAST\n",
       "23   Data_Entry_Method   Data_Entry_Method"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_names=pd.DataFrame()\n",
    "\n",
    "for table in observation_tables:\n",
    "    query=f'DESCRIBE {table}'\n",
    "    mycursor.execute(query)\n",
    "    columns=[]\n",
    "    for line in mycursor:\n",
    "        columns.append(line[0])\n",
    "    \n",
    "    temp_df=pd.DataFrame({table: columns})\n",
    "    column_names=pd.concat([column_names, temp_df], axis=1)\n",
    "\n",
    "column_names[['pfw_2021', 'pfw_1988']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because now all tables have the same number and order of columns, they can be merged into a bigger one.\n",
    "For this reason a new, empty table is created, where all others will be merged into."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query='CREATE TABLE IF NOT EXISTS observations LIKE pfw_1988'\n",
    "mycursor.execute(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the new table can be populated by merging all other tables into it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for table in observation_tables:\n",
    "    query=f'INSERT INTO observations SELECT * FROM {table}'\n",
    "    mycursor.execute(query)\n",
    "    print(f'{table} sucessfully inserted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the table can be inspected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query='DESCRIBE observations'\n",
    "mycursor.execute(query)\n",
    "for line in mycursor:\n",
    "    print(line)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5cc83d2eedb6ffb852fbb5dbaa9989f2c63275a766445ab272166a468a2180f7"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
