{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this file the data will be merged into on table for further processing.\n",
    "This will be done by connecting with the database and pass SQL querries through the connection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first, the required modules are imported:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import mysql.connector\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, the credentials are loaded and the connection to the database is etablished:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get credentials for MySQL/dbms\n",
    "with open(r'C:\\Users\\mathi\\Desktop\\Datenanalyse\\Credentials\\mysql.json') as json_file:\n",
    "    db_credentials = json.load(json_file)['MySQL']\n",
    "\n",
    "#credentials as variables\n",
    "host='localhost'\n",
    "user=db_credentials['user']\n",
    "password=db_credentials['password']\n",
    "database='feederwatch'\n",
    "\n",
    "#etablish connection to the dbms\n",
    "mydb = mysql.connector.connect(\n",
    "  host=host,\n",
    "  user=user,\n",
    "  password=password)\n",
    "\n",
    "mycursor = mydb.cursor()\n",
    "\n",
    "#select database\n",
    "query=f'USE {database}'\n",
    "mycursor.execute(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's controlled if all the tables are availible and how they are labled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('pfw_1988_1995_public',)\n",
      "('pfw_1996_2000_public',)\n",
      "('pfw_2001_2005_public',)\n",
      "('pfw_2006_2010_public',)\n",
      "('pfw_2011_2015_public',)\n",
      "('pfw_2016_2020_public',)\n",
      "('pfw_2021_public',)\n",
      "('pfw_count_site_data_public_2021',)\n"
     ]
    }
   ],
   "source": [
    "query='SHOW TABLES'\n",
    "mycursor.execute(query)\n",
    "for table in mycursor:\n",
    "    print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the names are just adopted from the original files, they are renamed into a shorter version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('pfw_1988',)\n",
      "('pfw_1996',)\n",
      "('pfw_2001',)\n",
      "('pfw_2006',)\n",
      "('pfw_2011',)\n",
      "('pfw_2016',)\n",
      "('pfw_2021',)\n",
      "('pfw_site_data',)\n"
     ]
    }
   ],
   "source": [
    "query='''RENAME TABLE\n",
    "        pfw_1988_1995_public TO pfw_1988,\n",
    "        pfw_1996_2000_public TO pfw_1996,\n",
    "        pfw_2001_2005_public TO pfw_2001,\n",
    "        pfw_2006_2010_public TO pfw_2006,\n",
    "        pfw_2011_2015_public TO pfw_2011,\n",
    "        pfw_2016_2020_public TO pfw_2016,\n",
    "        pfw_2021_public TO pfw_2021,\n",
    "        pfw_count_site_data_public_2021 TO pfw_site_data'''\n",
    "\n",
    "mycursor.execute(query)\n",
    "\n",
    "query='SHOW TABLES'\n",
    "mycursor.execute(query)\n",
    "for table in mycursor:\n",
    "    print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because it's expected that tables with data from different years have the same structure, they are grouped together to acess them easily with loops later on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pfw_2016', 'observations', 'pfw_1988', 'pfw_2001', 'pfw_2021', 'pfw_2006', 'pfw_2011', 'pfw_1996'}\n"
     ]
    }
   ],
   "source": [
    "observation_tables=set()\n",
    "query='SHOW TABLES'\n",
    "mycursor.execute(query)\n",
    "for table in mycursor:\n",
    "    observation_tables.add(table[0])\n",
    "\n",
    "observation_tables.discard('pfw_site_data') #removes site_data from set because it should be treated differently\n",
    "\n",
    "print(observation_tables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tables containing the observations should look all the same, and they contain the observations timestamp, they can be merged into a bigger one. Before this step is performed, it should be ensured that the tables all have the same column names and order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              pfw_1988            pfw_2001            pfw_2011  \\\n",
      "0                index               index               index   \n",
      "1               LOC_ID              LOC_ID              LOC_ID   \n",
      "2             LATITUDE            LATITUDE            LATITUDE   \n",
      "3            LONGITUDE           LONGITUDE           LONGITUDE   \n",
      "4    SUBNATIONAL1_CODE   SUBNATIONAL1_CODE   SUBNATIONAL1_CODE   \n",
      "5      ENTRY_TECHNIQUE     ENTRY_TECHNIQUE     ENTRY_TECHNIQUE   \n",
      "6               SUB_ID              SUB_ID              SUB_ID   \n",
      "7               OBS_ID              OBS_ID              OBS_ID   \n",
      "8                Month               Month               Month   \n",
      "9                  Day                 Day                 Day   \n",
      "10                Year                Year                Year   \n",
      "11      PROJ_PERIOD_ID      PROJ_PERIOD_ID      PROJ_PERIOD_ID   \n",
      "12        SPECIES_CODE        SPECIES_CODE        SPECIES_CODE   \n",
      "13            HOW_MANY            HOW_MANY            HOW_MANY   \n",
      "14           PLUS_CODE           PLUS_CODE           PLUS_CODE   \n",
      "15               VALID               VALID               VALID   \n",
      "16            REVIEWED            REVIEWED            REVIEWED   \n",
      "17             DAY1_AM             DAY1_AM             DAY1_AM   \n",
      "18             DAY1_PM             DAY1_PM             DAY1_PM   \n",
      "19             DAY2_AM             DAY2_AM             DAY2_AM   \n",
      "20             DAY2_PM             DAY2_PM             DAY2_PM   \n",
      "21  EFFORT_HRS_ATLEAST  EFFORT_HRS_ATLEAST  EFFORT_HRS_ATLEAST   \n",
      "22    SNOW_DEP_ATLEAST    SNOW_DEP_ATLEAST    SNOW_DEP_ATLEAST   \n",
      "23   Data_Entry_Method   Data_Entry_Method   Data_Entry_Method   \n",
      "\n",
      "              pfw_2006            pfw_1996            pfw_2016  \\\n",
      "0                index               index               index   \n",
      "1               LOC_ID              LOC_ID              LOC_ID   \n",
      "2             LATITUDE            LATITUDE            LATITUDE   \n",
      "3            LONGITUDE           LONGITUDE           LONGITUDE   \n",
      "4    SUBNATIONAL1_CODE   SUBNATIONAL1_CODE   SUBNATIONAL1_CODE   \n",
      "5      ENTRY_TECHNIQUE     ENTRY_TECHNIQUE     ENTRY_TECHNIQUE   \n",
      "6               SUB_ID              SUB_ID              SUB_ID   \n",
      "7               OBS_ID              OBS_ID              OBS_ID   \n",
      "8                Month               Month               Month   \n",
      "9                  Day                 Day                 Day   \n",
      "10                Year                Year                Year   \n",
      "11      PROJ_PERIOD_ID      PROJ_PERIOD_ID      PROJ_PERIOD_ID   \n",
      "12        SPECIES_CODE        SPECIES_CODE        SPECIES_CODE   \n",
      "13            HOW_MANY            HOW_MANY            HOW_MANY   \n",
      "14           PLUS_CODE           PLUS_CODE           PLUS_CODE   \n",
      "15               VALID               VALID               VALID   \n",
      "16            REVIEWED            REVIEWED            REVIEWED   \n",
      "17             DAY1_AM             DAY1_AM             DAY1_AM   \n",
      "18             DAY1_PM             DAY1_PM             DAY1_PM   \n",
      "19             DAY2_AM             DAY2_AM             DAY2_AM   \n",
      "20             DAY2_PM             DAY2_PM             DAY2_PM   \n",
      "21  EFFORT_HRS_ATLEAST  EFFORT_HRS_ATLEAST  EFFORT_HRS_ATLEAST   \n",
      "22    SNOW_DEP_ATLEAST    SNOW_DEP_ATLEAST    SNOW_DEP_ATLEAST   \n",
      "23   Data_Entry_Method   Data_Entry_Method   Data_Entry_Method   \n",
      "\n",
      "              pfw_2021  \n",
      "0                index  \n",
      "1               loc_id  \n",
      "2             latitude  \n",
      "3            longitude  \n",
      "4    subnational1_code  \n",
      "5      entry_technique  \n",
      "6               sub_id  \n",
      "7               obs_id  \n",
      "8                Month  \n",
      "9                  Day  \n",
      "10                Year  \n",
      "11      PROJ_PERIOD_ID  \n",
      "12        species_code  \n",
      "13            how_many  \n",
      "14               valid  \n",
      "15            reviewed  \n",
      "16             day1_am  \n",
      "17             day1_pm  \n",
      "18             day2_am  \n",
      "19             day2_pm  \n",
      "20  effort_hrs_atleast  \n",
      "21    snow_dep_atleast  \n",
      "22   Data_Entry_Method  \n",
      "23                 NaN  \n"
     ]
    }
   ],
   "source": [
    "column_names=pd.DataFrame()\n",
    "\n",
    "for table in observation_tables:\n",
    "    query=f'DESCRIBE {table}'\n",
    "    mycursor.execute(query)\n",
    "    columns=[]\n",
    "    for line in mycursor:\n",
    "        columns.append(line[0])\n",
    "    \n",
    "    temp_df=pd.DataFrame({table: columns})\n",
    "    column_names=pd.concat([column_names, temp_df], axis=1)\n",
    "\n",
    "print(column_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the output exceeds the size limit of a jupyter notebook cell (at least in VS Code), visual inspection dosn't work. \n",
    "Instead, a boolen matrix can be generated, where all column names are compared with each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          pfw_1988  pfw_2001  pfw_2011  pfw_2006  pfw_1996  pfw_2016  pfw_2021\n",
      "pfw_1988      True      True      True      True      True      True     False\n",
      "pfw_2001      True      True      True      True      True      True     False\n",
      "pfw_2011      True      True      True      True      True      True     False\n",
      "pfw_2006      True      True      True      True      True      True     False\n",
      "pfw_1996      True      True      True      True      True      True     False\n",
      "pfw_2016      True      True      True      True      True      True     False\n",
      "pfw_2021     False     False     False     False     False     False     False\n"
     ]
    }
   ],
   "source": [
    "as_np_array = column_names.values\n",
    "comparison_matrix = pd.DataFrame((as_np_array.T[:, None] == as_np_array.T).all(-1), column_names.columns, column_names.columns)\n",
    "print(comparison_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The comparison shows, that all tables have the same column names except 'pfw_2021'. For further investigation, the column names of 'pfw_2021' are displayed next to the names from another table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pfw_2021</th>\n",
       "      <th>pfw_1988</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>index</td>\n",
       "      <td>index</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>loc_id</td>\n",
       "      <td>LOC_ID</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>latitude</td>\n",
       "      <td>LATITUDE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>longitude</td>\n",
       "      <td>LONGITUDE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>subnational1_code</td>\n",
       "      <td>SUBNATIONAL1_CODE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>entry_technique</td>\n",
       "      <td>ENTRY_TECHNIQUE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>sub_id</td>\n",
       "      <td>SUB_ID</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>obs_id</td>\n",
       "      <td>OBS_ID</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Month</td>\n",
       "      <td>Month</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Day</td>\n",
       "      <td>Day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Year</td>\n",
       "      <td>Year</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>PROJ_PERIOD_ID</td>\n",
       "      <td>PROJ_PERIOD_ID</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>species_code</td>\n",
       "      <td>SPECIES_CODE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>how_many</td>\n",
       "      <td>HOW_MANY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>valid</td>\n",
       "      <td>PLUS_CODE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>reviewed</td>\n",
       "      <td>VALID</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>day1_am</td>\n",
       "      <td>REVIEWED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>day1_pm</td>\n",
       "      <td>DAY1_AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>day2_am</td>\n",
       "      <td>DAY1_PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>day2_pm</td>\n",
       "      <td>DAY2_AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>effort_hrs_atleast</td>\n",
       "      <td>DAY2_PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>snow_dep_atleast</td>\n",
       "      <td>EFFORT_HRS_ATLEAST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Data_Entry_Method</td>\n",
       "      <td>SNOW_DEP_ATLEAST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Data_Entry_Method</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              pfw_2021            pfw_1988\n",
       "0                index               index\n",
       "1               loc_id              LOC_ID\n",
       "2             latitude            LATITUDE\n",
       "3            longitude           LONGITUDE\n",
       "4    subnational1_code   SUBNATIONAL1_CODE\n",
       "5      entry_technique     ENTRY_TECHNIQUE\n",
       "6               sub_id              SUB_ID\n",
       "7               obs_id              OBS_ID\n",
       "8                Month               Month\n",
       "9                  Day                 Day\n",
       "10                Year                Year\n",
       "11      PROJ_PERIOD_ID      PROJ_PERIOD_ID\n",
       "12        species_code        SPECIES_CODE\n",
       "13            how_many            HOW_MANY\n",
       "14               valid           PLUS_CODE\n",
       "15            reviewed               VALID\n",
       "16             day1_am            REVIEWED\n",
       "17             day1_pm             DAY1_AM\n",
       "18             day2_am             DAY1_PM\n",
       "19             day2_pm             DAY2_AM\n",
       "20  effort_hrs_atleast             DAY2_PM\n",
       "21    snow_dep_atleast  EFFORT_HRS_ATLEAST\n",
       "22   Data_Entry_Method    SNOW_DEP_ATLEAST\n",
       "23                 NaN   Data_Entry_Method"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_names[['pfw_2021', 'pfw_1988']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A obvious differnce is, that they are written in differnt cases (lower/upper case). But because the case dosn't matter for merging the tables, this difference can be ignored. \n",
    "Another difference is visible in row 14, where one column is labeled 'valid' and the other 'PLUS_CODE'. It seems, that the column 'plus_code' is missing in 'pfw_2021', which leads to a shift and missmatch in all following columns and a NaN column at the end to fill up the data.\n",
    "To figure out, what the missing column 'plus_code' should ontain, the FeederWatch_Data_Dictonary.xlsx, provided by Project FeederWatch, was checked. \n",
    "According to this documentation it should contain a binary value:\n",
    "\n",
    ">\"Variable indicating if the total number of a species seen was larger than the value reported\".\n",
    "\n",
    "Even though this variable dosn't seem to be very interesting for analysis, it can be keept, and an empty column can be created for the table, where it's missing.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "query='''ALTER TABLE pfw_2021\n",
    "        ADD COLUMN plus_code BINARY NULL\n",
    "        AFTER how_many'''\n",
    "mycursor.execute(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To confirm the change, code from above is run again. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pfw_2021</th>\n",
       "      <th>pfw_1988</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>index</td>\n",
       "      <td>index</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>loc_id</td>\n",
       "      <td>LOC_ID</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>latitude</td>\n",
       "      <td>LATITUDE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>longitude</td>\n",
       "      <td>LONGITUDE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>subnational1_code</td>\n",
       "      <td>SUBNATIONAL1_CODE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>entry_technique</td>\n",
       "      <td>ENTRY_TECHNIQUE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>sub_id</td>\n",
       "      <td>SUB_ID</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>obs_id</td>\n",
       "      <td>OBS_ID</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Month</td>\n",
       "      <td>Month</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Day</td>\n",
       "      <td>Day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Year</td>\n",
       "      <td>Year</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>PROJ_PERIOD_ID</td>\n",
       "      <td>PROJ_PERIOD_ID</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>species_code</td>\n",
       "      <td>SPECIES_CODE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>how_many</td>\n",
       "      <td>HOW_MANY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>plus_code</td>\n",
       "      <td>PLUS_CODE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>valid</td>\n",
       "      <td>VALID</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>reviewed</td>\n",
       "      <td>REVIEWED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>day1_am</td>\n",
       "      <td>DAY1_AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>day1_pm</td>\n",
       "      <td>DAY1_PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>day2_am</td>\n",
       "      <td>DAY2_AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>day2_pm</td>\n",
       "      <td>DAY2_PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>effort_hrs_atleast</td>\n",
       "      <td>EFFORT_HRS_ATLEAST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>snow_dep_atleast</td>\n",
       "      <td>SNOW_DEP_ATLEAST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Data_Entry_Method</td>\n",
       "      <td>Data_Entry_Method</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              pfw_2021            pfw_1988\n",
       "0                index               index\n",
       "1               loc_id              LOC_ID\n",
       "2             latitude            LATITUDE\n",
       "3            longitude           LONGITUDE\n",
       "4    subnational1_code   SUBNATIONAL1_CODE\n",
       "5      entry_technique     ENTRY_TECHNIQUE\n",
       "6               sub_id              SUB_ID\n",
       "7               obs_id              OBS_ID\n",
       "8                Month               Month\n",
       "9                  Day                 Day\n",
       "10                Year                Year\n",
       "11      PROJ_PERIOD_ID      PROJ_PERIOD_ID\n",
       "12        species_code        SPECIES_CODE\n",
       "13            how_many            HOW_MANY\n",
       "14           plus_code           PLUS_CODE\n",
       "15               valid               VALID\n",
       "16            reviewed            REVIEWED\n",
       "17             day1_am             DAY1_AM\n",
       "18             day1_pm             DAY1_PM\n",
       "19             day2_am             DAY2_AM\n",
       "20             day2_pm             DAY2_PM\n",
       "21  effort_hrs_atleast  EFFORT_HRS_ATLEAST\n",
       "22    snow_dep_atleast    SNOW_DEP_ATLEAST\n",
       "23   Data_Entry_Method   Data_Entry_Method"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_names=pd.DataFrame()\n",
    "\n",
    "for table in observation_tables:\n",
    "    query=f'DESCRIBE {table}'\n",
    "    mycursor.execute(query)\n",
    "    columns=[]\n",
    "    for line in mycursor:\n",
    "        columns.append(line[0])\n",
    "    \n",
    "    temp_df=pd.DataFrame({table: columns})\n",
    "    column_names=pd.concat([column_names, temp_df], axis=1)\n",
    "\n",
    "column_names[['pfw_2021', 'pfw_1988']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because now all tables have the same number and order of columns, they can be merged into a bigger one.\n",
    "For this reason a new, empty table is created, where all others will be merged into."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "query='CREATE TABLE IF NOT EXISTS observations LIKE pfw_1988'\n",
    "mycursor.execute(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because of the size of the tables, a normal insert query might create an DatabaseError (1206 (HY000): The total number of locks exceeds the lock table size). \n",
    "This can be avoided by inserting small chunks. The easiest way to do this, is by using an statement like this:\n",
    "\n",
    ">WHERE id> i\n",
    ">ORDER BY id ASC\n",
    ">LIMIT chunkSize\n",
    ">id=id+chunkSize\n",
    "\n",
    "To run such a query an integer id is required. The tables have a column called OBS_ID, which can be ispected to check, if it can be used for such purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('OBS217571888',)\n",
      "('OBS217571889',)\n",
      "('OBS217572168',)\n",
      "('OBS219656334',)\n",
      "('OBS219657237',)\n",
      "('OBS219657661',)\n",
      "('OBS224435761',)\n",
      "('OBS224436034',)\n",
      "('OBS224452237',)\n",
      "('OBS224452938',)\n"
     ]
    }
   ],
   "source": [
    "query='SELECT OBS_ID FROM pfw_1988 ORDER BY OBS_ID LIMIT 10'\n",
    "mycursor.execute(query)\n",
    "for line in mycursor:\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It turned out, that the OBS_ID increases, but the values are strings and a lot of numbers are missing inbetween.\n",
    "To get a continues intiger, an auto incrementing primary key is created.\n",
    "To avoid issues during insertion, the table observation dosn't get a key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pfw_1988: Primary Key added\n",
      "pfw_2001: Primary Key added\n",
      "pfw_2011: Primary Key added\n",
      "pfw_2006: Primary Key added\n",
      "pfw_1996: Primary Key added\n",
      "pfw_2016: Primary Key added\n",
      "pfw_2021: Primary Key added\n",
      "observations: Column ID added\n"
     ]
    }
   ],
   "source": [
    "for table in observation_tables:\n",
    "    query=f'ALTER TABLE {table} ADD ID INT NOT NULL AUTO_INCREMENT, ADD PRIMARY KEY (ID)'\n",
    "    mycursor.execute(query)\n",
    "    print(f'{table}: Primary Key added')\n",
    "\n",
    "#and the observation table as well\n",
    "table='observations'\n",
    "query=f'ALTER TABLE {table} ADD ID INT NOT NULL'\n",
    "mycursor.execute(query)\n",
    "print(f'{table}: Column ID added')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the new table can be populated by inserting the data from all other tables into it.\n",
    "This is done chunk-wise to avoid memory issues, and in addition the default innodb_buffer_pool_size was increased."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pfw_2016 sucessfully inserted\n",
      "pfw_1988 sucessfully inserted\n",
      "pfw_2001 sucessfully inserted\n",
      "pfw_2021 sucessfully inserted\n",
      "pfw_2006 sucessfully inserted\n",
      "pfw_2011 sucessfully inserted\n",
      "pfw_1996 sucessfully inserted\n"
     ]
    }
   ],
   "source": [
    "chunk_size=100000\n",
    "\n",
    "for table in observation_tables:\n",
    "    lower_limit=1\n",
    "    upper_limit=lower_limit+chunk_size-1 #sql BETWEEN is inclusive \n",
    "    query=f'SELECT MAX(ID) FROM {table}'\n",
    "    \n",
    "    mycursor.execute(query)\n",
    "    for line in mycursor:\n",
    "        number_of_rows=line[0]\n",
    "\n",
    "    while lower_limit<=number_of_rows:\n",
    "        query1='INSERT INTO observations '\n",
    "        query2=f'(SELECT * FROM {table} WHERE ID BETWEEN {lower_limit} AND {upper_limit})'\n",
    "        query=query1+query2\n",
    "        mycursor.execute(query)\n",
    "        lower_limit=upper_limit+1\n",
    "        upper_limit=lower_limit+chunk_size-1\n",
    "\n",
    "    print(f'{table} sucessfully inserted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next steps, cleaning and transformation of the actual data, are performed in a different file."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5cc83d2eedb6ffb852fbb5dbaa9989f2c63275a766445ab272166a468a2180f7"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
